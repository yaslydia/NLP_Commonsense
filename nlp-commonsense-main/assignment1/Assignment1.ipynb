{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "from typing import Dict, List, Set, Tuple, Union\n",
    "import itertools\n",
    "\n",
    "import spacy\n",
    "\n",
    "import utils as U\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "stopwords = set(nlp.Defaults.stop_words).union({\",\", \".\", \"?\", \":\", \";\"})\n",
    "\n",
    "\n",
    "def load_examples() -> List[Dict[str, Union[str, List[str]]]]:\n",
    "    \"\"\"Quick and dirty parser to turn examples.txt into a machine-readable form.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[dict[str, Union[str, list[str]]]]\n",
    "        list of examples. Each examples is of the form\n",
    "            {\n",
    "                \"question\": QUESTION,\n",
    "                \"context\": CONTEXT or \"\",\n",
    "                \"choices\": [CHOICE1, CHOICE2, ...]\n",
    "            }\n",
    "    \"\"\"\n",
    "\n",
    "    with open(\"../data/raw/examples.txt\") as fp:\n",
    "        data = fp.read()\n",
    "\n",
    "    examples = data.split(\"#\")[1:]\n",
    "\n",
    "    parsed = []\n",
    "\n",
    "    for e in examples:\n",
    "        parts = e.split(\"\\n\")\n",
    "\n",
    "        question = next(\n",
    "            (\n",
    "                U.removeprefix(p, \"Question:\").strip()\n",
    "                for p in parts\n",
    "                if p.startswith(\"Question: \")\n",
    "            ),\n",
    "            \"\",\n",
    "        )\n",
    "        context = next(\n",
    "            (\n",
    "                U.removeprefix(p, \"Context:\").strip()\n",
    "                for p in parts\n",
    "                if p.startswith(\"Context: \")\n",
    "            ),\n",
    "            \"\",\n",
    "        )\n",
    "        choices = [p.split(\")\")[1].strip() for p in parts if p.startswith(\"(\")]\n",
    "\n",
    "        parsed.append({\"question\": question, \"context\": context, \"choices\": choices})\n",
    "\n",
    "    return parsed\n",
    "\n",
    "def extract_terms_from_example(example: dict) -> Tuple[Set[str], Set[str]]:\n",
    "    \"\"\"extract terms from an example using `extract_terms`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    example : dict\n",
    "        example as returned by `load_examples`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    set[str]\n",
    "        all terms appearing in question and context\n",
    "    set[str]]\n",
    "        all terms appearing in one of the answer choices\n",
    "    \"\"\"\n",
    "\n",
    "    question_context = set(\n",
    "        itertools.chain(\n",
    "            extract_terms(example[\"question\"]), extract_terms(example[\"context\"])\n",
    "        )\n",
    "    )\n",
    "\n",
    "    choices = set(\n",
    "        itertools.chain.from_iterable(extract_terms(c) for c in example[\"choices\"])\n",
    "    )\n",
    "\n",
    "    return question_context, choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from functools import reduce\n",
    "import operator\n",
    "from typing import Dict, Iterable, List, NamedTuple, Set, Tuple\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import joblib\n",
    "\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "__lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "class EdgeDescriptor(NamedTuple):\n",
    "    \"\"\"Describes an edge in ConceptNet.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    label_idx:\n",
    "        index of the edge label in labels_idx2name\n",
    "    weight:\n",
    "        weight of the edge\n",
    "    row_idx:\n",
    "        index of the edge in \"en_edges.csv\" (for further information lookup if necessary)\n",
    "    \"\"\"\n",
    "\n",
    "    label_idx : int\n",
    "    weight : float\n",
    "    row_idx : int\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ConceptNet:\n",
    "    \"\"\"This class contains the filtered and processed representation of the ConceptNet knowledge \n",
    "    graph.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "\n",
    "    nodes_idx2name:\n",
    "        mapping node indices to normalized node names\n",
    "    nodes_name2idx:\n",
    "        mapping node names to indices\n",
    "\n",
    "    labels_idx2name:\n",
    "        mapping edge label indices to labels\n",
    "    labels_name2idx:\n",
    "        mapping edge labels to indices\n",
    "\n",
    "    adjacency_lists:\n",
    "        contains a list of neighbors for each node (indices are used). graph is represented as \n",
    "        undirected.\n",
    "    edge_descriptors:\n",
    "        maps a pair of indices to all direct edges in ConceptNet between this two nodes. edges are described via EdgeDescriptors. Edges are treated as *directed* here, i.e. if an edge is in `adjacency_lists`, but not in `edge_descriptors` it is an edge not originally present in ConceptNet and one must look up the reverse edge in `edge_descriptor`.\n",
    "    \"\"\"\n",
    "\n",
    "    nodes_idx2name : List[str]\n",
    "    nodes_name2idx : Dict[str, int]\n",
    "\n",
    "    labels_idx2name : List[str]\n",
    "    labels_name2idx : Dict[str, int]\n",
    "\n",
    "    adjacency_lists : Dict[int, Set[int]]\n",
    "    edge_descriptors : Dict[Tuple[int, int], Set[EdgeDescriptor]]\n",
    "\n",
    "def removeprefix(s: str, prefix: str) -> str:\n",
    "    if s.startswith(prefix):\n",
    "        return s[len(prefix):]\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "def normalize_conceptnet(s: str) -> str:\n",
    "    \"\"\"Normalize a ConceptNet node to ensure that matching between example words and nodes in \n",
    "    ConceptNet works.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    s : str\n",
    "        string to normalize\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        normalized string\n",
    "    \"\"\"\n",
    "\n",
    "    s = removeprefix(s, \"/c/en/\")\n",
    "    s = s.split(\"/\")[0] # remove the optionally added (/n, /v, ...)\n",
    "    s = s.replace(\"_\", \" \")\n",
    "    s = s.casefold()\n",
    "    s = __lemmatizer.lemmatize(s)\n",
    "\n",
    "    return s\n",
    "\n",
    "def normalize_input(s: str) -> str:\n",
    "    \"\"\"Normalize a input token to ensure that matching between example words and nodes in \n",
    "    ConceptNet works.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    s : str\n",
    "        string to normalize\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        normalized string\n",
    "    \"\"\"\n",
    "    # TODO switch to Spacy lemmatization\n",
    "\n",
    "    s = s.casefold()\n",
    "    s = __lemmatizer.lemmatize(s)\n",
    "\n",
    "    return s\n",
    "\n",
    "def prod(vals: Iterable[float]) -> float:\n",
    "    return reduce(operator.mul, vals, 1)\n",
    "\n",
    "def load_conceptnet(load_compressed: bool =False) -> ConceptNet:\n",
    "\n",
    "    if load_compressed:\n",
    "        return joblib.load(\"../data/processed/graph_representation_compressed.joblib\")\n",
    "    else:\n",
    "        return joblib.load(\"../data/processed/graph_representation.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Iterable, List, Union\n",
    "import logging\n",
    "\n",
    "from utils import ConceptNet, normalize_input\n",
    "from renderer import render_path_brief\n",
    "\n",
    "\n",
    "def search_shortest_path(\n",
    "    start_idx: int,\n",
    "    end_idx: int,\n",
    "    adjacency_lists: Dict[int, Iterable[int]],\n",
    "    max_path_len,\n",
    ") -> list:\n",
    "    \"\"\"the actual implementation of a BFS. This function is completely agnostic about ConceptNet, \n",
    "    it just works with adjacency lists of integers.\"\"\"\n",
    "\n",
    "    queue = [\n",
    "        (start_idx, 0)\n",
    "    ]  # nodes to be processed (tuple of node and path length to start node)\n",
    "    predecessor_idx = {\n",
    "        start_idx: -1\n",
    "    }  # visited nodes, mapping each node to the idx of its predecessor\n",
    "\n",
    "    while queue:\n",
    "        node, path_len = queue.pop(0)\n",
    "\n",
    "        #logging.debug(f\"Processing {node} (path len {path_len})\")\n",
    "\n",
    "        if node == end_idx:\n",
    "\n",
    "            #logging.debug(\"  Final node, building path\")\n",
    "\n",
    "            # build path in reverse\n",
    "            path = [node]\n",
    "\n",
    "            pred = predecessor_idx[node]\n",
    "            while pred != -1:\n",
    "                #logging.debug(f\"    {pred}\")\n",
    "                path.insert(0, pred)\n",
    "                pred = predecessor_idx[pred]\n",
    "\n",
    "            return path\n",
    "\n",
    "        for neighbour in adjacency_lists[node]:\n",
    "            if neighbour in predecessor_idx:\n",
    "                continue\n",
    "\n",
    "            #logging.debug(f\"  Processing unseen neighbor {neighbour}\")\n",
    "\n",
    "            predecessor_idx[neighbour] = node\n",
    "\n",
    "            if path_len + 1 < max_path_len:\n",
    "                #logging.debug(\"   Adding node to queue\")\n",
    "                queue.append((neighbour, path_len + 1))\n",
    "\n",
    "    return []\n",
    "\n",
    "\n",
    "def find_word_path(\n",
    "        start_term: str, end_term: str, \n",
    "        graph: ConceptNet, \n",
    "        max_path_len: int =3,\n",
    "        renderer=render_path_brief) -> Union[str, List[int]]:\n",
    "    \"\"\"Find the shortest path between `start_term` and `end_term` and return its textual \n",
    "    representation. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    start_term : str\n",
    "        start term for path search\n",
    "    end_term : str\n",
    "        end term for path search\n",
    "    graph : ConceptNet\n",
    "        ConceptNet instance to work with\n",
    "    max_path_len : int, optional\n",
    "        maximal number of nodes in a path, by default 3\n",
    "    renderer, optional\n",
    "        function to visualize paths, by default render_path_brief. If None, the raw path (a list of int's) is returned.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        path visualization\n",
    "    list[int]\n",
    "        raw path, only returned if renderer is None\n",
    "    \"\"\"\n",
    "\n",
    "    start_term = normalize_input(start_term)\n",
    "    end_term = normalize_input(end_term)\n",
    "\n",
    "    #logging.info(f\"after normalization: {start_term}, {end_term}\")\n",
    "\n",
    "    if start_term in graph.nodes_name2idx:\n",
    "        start_idx = graph.nodes_name2idx[start_term]\n",
    "    else:\n",
    "        #logging.warning(f\"start {start_term} not in graph, skipping\")\n",
    "        return []\n",
    "\n",
    "    if end_term in graph.nodes_name2idx:\n",
    "        end_idx = graph.nodes_name2idx[end_term]\n",
    "    else:\n",
    "        #logging.warning(f\"end {end_term} not in graph, skipping\")\n",
    "        return []\n",
    "\n",
    "    path = search_shortest_path(\n",
    "        start_idx, end_idx, graph.adjacency_lists, max_path_len=max_path_len\n",
    "    )\n",
    "\n",
    "    if renderer:\n",
    "        return renderer(path, graph)\n",
    "    else:\n",
    "        return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = load_examples() # load examples.txt in machine-readable form\n",
    "conceptnet = load_conceptnet() # load preprocessed ConceptNet pickle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Terms From Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'bag',\n",
       "  'baggage',\n",
       "  'checked',\n",
       "  'drawstring',\n",
       "  'drawstring bag',\n",
       "  'heading',\n",
       "  'only baggage',\n",
       "  'wa',\n",
       "  'woman'},\n",
       " {'airport',\n",
       "  'garbage',\n",
       "  'jewelry',\n",
       "  'jewelry store',\n",
       "  'military',\n",
       "  'safe',\n",
       "  'store'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_terms_example(examples[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_word_path(\"safe\", \"baggage\", conceptnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'safe --RelatedTo--> heavy <--RelatedTo-- carry --Antonym--> baggage'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path length with four\n",
    "find_word_path(\"safe\", \"baggage\", conceptnet, max_path_len=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checked --HasContext--> north america --HasContext--> canada <--HasContext-- garbage'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_word_path(\"checked\", \"garbage\", conceptnet, max_path_len=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'excited <--HasSubevent-- score home run --HasPrerequisite--> play baseball --HasPrerequisite--> apply'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_word_path(\"excited\", \"apply\", conceptnet, max_path_len=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'safe --RelatedTo--> heavy <--RelatedTo-- carry --Antonym--> baggage'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_word_path(\"safe\", \"baggage\", conceptnet, max_path_len=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]WARNING:root:start_term='only baggage' not in graph, skipping\n",
      "WARNING:root:start_term='only baggage' not in graph, skipping\n",
      "WARNING:root:start_term='only baggage' not in graph, skipping\n",
      "WARNING:root:start_term='only baggage' not in graph, skipping\n",
      "WARNING:root:start_term='only baggage' not in graph, skipping\n",
      "WARNING:root:start_term='only baggage' not in graph, skipping\n",
      "WARNING:root:start_term='only baggage' not in graph, skipping\n",
      " 20%|██        | 2/10 [01:00<03:53, 29.22s/it]WARNING:root:end_term='his enemy' not in graph, skipping\n",
      "WARNING:root:end_term='his enemy' not in graph, skipping\n",
      "WARNING:root:end_term='his enemy' not in graph, skipping\n",
      "WARNING:root:end_term='his enemy' not in graph, skipping\n",
      "WARNING:root:end_term='his enemy' not in graph, skipping\n",
      "WARNING:root:end_term='his enemy' not in graph, skipping\n",
      "WARNING:root:end_term='his enemy' not in graph, skipping\n",
      "WARNING:root:start_term='his enemy' not in graph, skipping\n",
      "WARNING:root:start_term='his enemy' not in graph, skipping\n",
      "WARNING:root:start_term='his enemy' not in graph, skipping\n",
      "WARNING:root:start_term='his enemy' not in graph, skipping\n",
      "WARNING:root:start_term='his enemy' not in graph, skipping\n",
      " 30%|███       | 3/10 [01:22<03:01, 25.86s/it]WARNING:root:start_term='his house' not in graph, skipping\n",
      "WARNING:root:start_term='his house' not in graph, skipping\n",
      "WARNING:root:start_term='his house' not in graph, skipping\n",
      "WARNING:root:start_term='his house' not in graph, skipping\n",
      "WARNING:root:start_term='his house' not in graph, skipping\n",
      "WARNING:root:start_term='his house' not in graph, skipping\n",
      "WARNING:root:start_term='his house' not in graph, skipping\n",
      "WARNING:root:start_term='his parents' not in graph, skipping\n",
      "WARNING:root:start_term='his parents' not in graph, skipping\n",
      "WARNING:root:start_term='his parents' not in graph, skipping\n",
      "WARNING:root:start_term='his parents' not in graph, skipping\n",
      "WARNING:root:start_term='his parents' not in graph, skipping\n",
      "WARNING:root:start_term='his parents' not in graph, skipping\n",
      "WARNING:root:start_term='his parents' not in graph, skipping\n",
      "WARNING:root:start_term=\"alex's parents\" not in graph, skipping\n",
      "WARNING:root:start_term=\"alex's parents\" not in graph, skipping\n",
      "WARNING:root:start_term=\"alex's parents\" not in graph, skipping\n",
      "WARNING:root:start_term=\"alex's parents\" not in graph, skipping\n",
      "WARNING:root:start_term=\"alex's parents\" not in graph, skipping\n",
      "WARNING:root:start_term=\"alex's parents\" not in graph, skipping\n",
      "WARNING:root:start_term=\"alex's parents\" not in graph, skipping\n",
      " 40%|████      | 4/10 [01:56<02:55, 29.32s/it]WARNING:root:start_term='skylar' not in graph, skipping\n",
      "WARNING:root:start_term='skylar' not in graph, skipping\n",
      "WARNING:root:start_term='skylar' not in graph, skipping\n",
      "WARNING:root:start_term='skylar' not in graph, skipping\n",
      "WARNING:root:start_term='skylar' not in graph, skipping\n",
      "WARNING:root:start_term='skylar' not in graph, skipping\n",
      "WARNING:root:start_term='skylar' not in graph, skipping\n",
      " 50%|█████     | 5/10 [02:22<02:20, 28.05s/it]WARNING:root:start_term='giant pile' not in graph, skipping\n",
      "WARNING:root:start_term='giant pile' not in graph, skipping\n",
      " 60%|██████    | 6/10 [02:30<01:24, 21.03s/it]WARNING:root:start_term='not lawrence' not in graph, skipping\n",
      "WARNING:root:start_term='not lawrence' not in graph, skipping\n",
      "WARNING:root:start_term='interested kevin' not in graph, skipping\n",
      "WARNING:root:start_term='interested kevin' not in graph, skipping\n",
      " 70%|███████   | 7/10 [02:54<01:06, 22.04s/it]WARNING:root:end_term='another credit card' not in graph, skipping\n",
      "WARNING:root:end_term='another credit card' not in graph, skipping\n",
      "WARNING:root:start_term='so much money' not in graph, skipping\n",
      "WARNING:root:start_term='so much money' not in graph, skipping\n",
      "WARNING:root:start_term='so much money' not in graph, skipping\n",
      "WARNING:root:start_term='so much money' not in graph, skipping\n",
      "WARNING:root:start_term='so much money' not in graph, skipping\n",
      "WARNING:root:start_term='so much money' not in graph, skipping\n",
      "WARNING:root:start_term='so much money' not in graph, skipping\n",
      "WARNING:root:start_term='so much money' not in graph, skipping\n",
      "WARNING:root:start_term='so much money' not in graph, skipping\n",
      "WARNING:root:end_term='another credit card' not in graph, skipping\n",
      "WARNING:root:end_term='another credit card' not in graph, skipping\n",
      "WARNING:root:start_term='$10,000 debt' not in graph, skipping\n",
      "WARNING:root:start_term='$10,000 debt' not in graph, skipping\n",
      "WARNING:root:start_term='$10,000 debt' not in graph, skipping\n",
      "WARNING:root:start_term='$10,000 debt' not in graph, skipping\n",
      "WARNING:root:start_term='$10,000 debt' not in graph, skipping\n",
      "WARNING:root:start_term='$10,000 debt' not in graph, skipping\n",
      "WARNING:root:start_term='$10,000 debt' not in graph, skipping\n",
      "WARNING:root:start_term='$10,000 debt' not in graph, skipping\n",
      "WARNING:root:start_term='$10,000 debt' not in graph, skipping\n",
      "WARNING:root:start_term='$' not in graph, skipping\n",
      "WARNING:root:start_term='$' not in graph, skipping\n",
      "WARNING:root:start_term='$' not in graph, skipping\n",
      "WARNING:root:start_term='$' not in graph, skipping\n",
      "WARNING:root:start_term='$' not in graph, skipping\n",
      "WARNING:root:start_term='$' not in graph, skipping\n",
      "WARNING:root:start_term='$' not in graph, skipping\n",
      "WARNING:root:start_term='$' not in graph, skipping\n",
      "WARNING:root:start_term='$' not in graph, skipping\n",
      "WARNING:root:end_term='another credit card' not in graph, skipping\n",
      "WARNING:root:start_term='next sentence' not in graph, skipping\n",
      "WARNING:root:start_term='next sentence' not in graph, skipping\n",
      "WARNING:root:start_term='next sentence' not in graph, skipping\n",
      "WARNING:root:start_term='next sentence' not in graph, skipping\n",
      "WARNING:root:start_term='next sentence' not in graph, skipping\n",
      "WARNING:root:start_term='next sentence' not in graph, skipping\n",
      "WARNING:root:start_term='next sentence' not in graph, skipping\n",
      "WARNING:root:start_term='next sentence' not in graph, skipping\n",
      "WARNING:root:start_term='next sentence' not in graph, skipping\n",
      "WARNING:root:end_term='another credit card' not in graph, skipping\n",
      "WARNING:root:start_term='his first credit card' not in graph, skipping\n",
      "WARNING:root:start_term='his first credit card' not in graph, skipping\n",
      "WARNING:root:start_term='his first credit card' not in graph, skipping\n",
      "WARNING:root:start_term='his first credit card' not in graph, skipping\n",
      "WARNING:root:start_term='his first credit card' not in graph, skipping\n",
      "WARNING:root:start_term='his first credit card' not in graph, skipping\n",
      "WARNING:root:start_term='his first credit card' not in graph, skipping\n",
      "WARNING:root:start_term='his first credit card' not in graph, skipping\n",
      "WARNING:root:start_term='his first credit card' not in graph, skipping\n",
      "WARNING:root:end_term='another credit card' not in graph, skipping\n",
      "WARNING:root:end_term='another credit card' not in graph, skipping\n",
      "WARNING:root:end_term='another credit card' not in graph, skipping\n",
      "WARNING:root:end_term='another credit card' not in graph, skipping\n",
      "WARNING:root:end_term='another credit card' not in graph, skipping\n",
      "WARNING:root:end_term='another credit card' not in graph, skipping\n",
      "WARNING:root:end_term='another credit card' not in graph, skipping\n",
      "WARNING:root:start_term='his card' not in graph, skipping\n",
      "WARNING:root:start_term='his card' not in graph, skipping\n",
      "WARNING:root:start_term='his card' not in graph, skipping\n",
      "WARNING:root:start_term='his card' not in graph, skipping\n",
      "WARNING:root:start_term='his card' not in graph, skipping\n",
      "WARNING:root:start_term='his card' not in graph, skipping\n",
      "WARNING:root:start_term='his card' not in graph, skipping\n",
      "WARNING:root:start_term='his card' not in graph, skipping\n",
      "WARNING:root:start_term='his card' not in graph, skipping\n",
      "WARNING:root:end_term='another credit card' not in graph, skipping\n",
      "WARNING:root:end_term='another credit card' not in graph, skipping\n",
      "WARNING:root:end_term='another credit card' not in graph, skipping\n",
      "WARNING:root:end_term='another credit card' not in graph, skipping\n",
      " 80%|████████  | 8/10 [04:11<01:19, 39.62s/it]WARNING:root:end_term='45-acre horse farm' not in graph, skipping\n",
      "WARNING:root:end_term='-' not in graph, skipping\n",
      "WARNING:root:end_term='45-acre horse farm' not in graph, skipping\n",
      "WARNING:root:end_term='-' not in graph, skipping\n",
      "WARNING:root:start_term='l.' not in graph, skipping\n",
      "WARNING:root:start_term='l.' not in graph, skipping\n",
      "WARNING:root:start_term='l.' not in graph, skipping\n",
      "WARNING:root:start_term='l.' not in graph, skipping\n",
      "WARNING:root:start_term='l.' not in graph, skipping\n",
      "WARNING:root:start_term='l.' not in graph, skipping\n",
      "WARNING:root:start_term='l.' not in graph, skipping\n",
      "WARNING:root:start_term='l.' not in graph, skipping\n",
      "WARNING:root:start_term='l.' not in graph, skipping\n",
      "WARNING:root:start_term='l.' not in graph, skipping\n",
      "WARNING:root:start_term='l.' not in graph, skipping\n",
      "WARNING:root:start_term='l.' not in graph, skipping\n",
      "WARNING:root:start_term='l.' not in graph, skipping\n",
      "WARNING:root:start_term='l.' not in graph, skipping\n",
      "WARNING:root:start_term='l.' not in graph, skipping\n",
      "WARNING:root:end_term='45-acre horse farm' not in graph, skipping\n",
      "WARNING:root:end_term='-' not in graph, skipping\n",
      "WARNING:root:start_term='st.' not in graph, skipping\n",
      "WARNING:root:start_term='st.' not in graph, skipping\n",
      "WARNING:root:start_term='st.' not in graph, skipping\n",
      "WARNING:root:start_term='st.' not in graph, skipping\n",
      "WARNING:root:start_term='st.' not in graph, skipping\n",
      "WARNING:root:start_term='st.' not in graph, skipping\n",
      "WARNING:root:start_term='st.' not in graph, skipping\n",
      "WARNING:root:start_term='st.' not in graph, skipping\n",
      "WARNING:root:start_term='st.' not in graph, skipping\n",
      "WARNING:root:start_term='st.' not in graph, skipping\n",
      "WARNING:root:start_term='st.' not in graph, skipping\n",
      "WARNING:root:start_term='st.' not in graph, skipping\n",
      "WARNING:root:start_term='st.' not in graph, skipping\n",
      "WARNING:root:start_term='st.' not in graph, skipping\n",
      "WARNING:root:start_term='st.' not in graph, skipping\n",
      "WARNING:root:end_term='45-acre horse farm' not in graph, skipping\n",
      "WARNING:root:end_term='-' not in graph, skipping\n",
      "WARNING:root:end_term='45-acre horse farm' not in graph, skipping\n",
      "WARNING:root:end_term='-' not in graph, skipping\n",
      "WARNING:root:end_term='45-acre horse farm' not in graph, skipping\n",
      "WARNING:root:end_term='-' not in graph, skipping\n",
      "WARNING:root:end_term='45-acre horse farm' not in graph, skipping\n",
      "WARNING:root:end_term='-' not in graph, skipping\n",
      "WARNING:root:end_term='45-acre horse farm' not in graph, skipping\n",
      "WARNING:root:end_term='-' not in graph, skipping\n",
      "WARNING:root:start_term='l. mark bailey' not in graph, skipping\n",
      "WARNING:root:start_term='l. mark bailey' not in graph, skipping\n",
      "WARNING:root:start_term='l. mark bailey' not in graph, skipping\n",
      "WARNING:root:start_term='l. mark bailey' not in graph, skipping\n",
      "WARNING:root:start_term='l. mark bailey' not in graph, skipping\n",
      "WARNING:root:start_term='l. mark bailey' not in graph, skipping\n",
      "WARNING:root:start_term='l. mark bailey' not in graph, skipping\n",
      "WARNING:root:start_term='l. mark bailey' not in graph, skipping\n",
      "WARNING:root:start_term='l. mark bailey' not in graph, skipping\n",
      "WARNING:root:start_term='l. mark bailey' not in graph, skipping\n",
      "WARNING:root:start_term='l. mark bailey' not in graph, skipping\n",
      "WARNING:root:start_term='l. mark bailey' not in graph, skipping\n",
      "WARNING:root:start_term='l. mark bailey' not in graph, skipping\n",
      "WARNING:root:start_term='l. mark bailey' not in graph, skipping\n",
      "WARNING:root:start_term='l. mark bailey' not in graph, skipping\n",
      "WARNING:root:start_term='st. paul' not in graph, skipping\n",
      "WARNING:root:start_term='st. paul' not in graph, skipping\n",
      "WARNING:root:start_term='st. paul' not in graph, skipping\n",
      "WARNING:root:start_term='st. paul' not in graph, skipping\n",
      "WARNING:root:start_term='st. paul' not in graph, skipping\n",
      "WARNING:root:start_term='st. paul' not in graph, skipping\n",
      "WARNING:root:start_term='st. paul' not in graph, skipping\n",
      "WARNING:root:start_term='st. paul' not in graph, skipping\n",
      "WARNING:root:start_term='st. paul' not in graph, skipping\n",
      "WARNING:root:start_term='st. paul' not in graph, skipping\n",
      "WARNING:root:start_term='st. paul' not in graph, skipping\n",
      "WARNING:root:start_term='st. paul' not in graph, skipping\n",
      "WARNING:root:start_term='st. paul' not in graph, skipping\n",
      "WARNING:root:start_term='st. paul' not in graph, skipping\n",
      "WARNING:root:start_term='st. paul' not in graph, skipping\n",
      "WARNING:root:end_term='45-acre horse farm' not in graph, skipping\n",
      "WARNING:root:end_term='-' not in graph, skipping\n",
      "WARNING:root:end_term='45-acre horse farm' not in graph, skipping\n",
      "WARNING:root:end_term='-' not in graph, skipping\n",
      "100%|██████████| 10/10 [07:08<00:00, 42.82s/it]\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "for idx, example in enumerate(tqdm(examples), start=1):\n",
    "    question_context, choices = extract_terms_example(example)\n",
    "\n",
    "    for tq in question_context:\n",
    "        for tc in choices:\n",
    "            p = find_word_path(tq, tc, conceptnet)\n",
    "\n",
    "            result.append(\n",
    "                {\n",
    "                    \"example\": idx,\n",
    "                    \"question_context\": tq,\n",
    "                    \"choices\": tc,\n",
    "                    \"path\": p,\n",
    "                }\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example</th>\n",
       "      <th>question_context</th>\n",
       "      <th>choices</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>drawstring</td>\n",
       "      <td>military</td>\n",
       "      <td>drawstring --PartOf--&gt; drawstring bag --AtLoca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>drawstring</td>\n",
       "      <td>jewelry</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>drawstring</td>\n",
       "      <td>jewelry store</td>\n",
       "      <td>drawstring --PartOf--&gt; drawstring bag --AtLoca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>drawstring</td>\n",
       "      <td>safe</td>\n",
       "      <td>drawstring --PartOf--&gt; drawstring bag --AtLoca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>drawstring</td>\n",
       "      <td>store</td>\n",
       "      <td>drawstring --PartOf--&gt; drawstring bag --AtLoca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>10</td>\n",
       "      <td>water</td>\n",
       "      <td>lift</td>\n",
       "      <td>water --HasContext--&gt; dialectal &lt;--HasContext-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>10</td>\n",
       "      <td>water</td>\n",
       "      <td>bottle</td>\n",
       "      <td>water --AtLocation--&gt; bottle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>10</td>\n",
       "      <td>water</td>\n",
       "      <td>suction</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>10</td>\n",
       "      <td>water</td>\n",
       "      <td>press</td>\n",
       "      <td>water &lt;--RelatedTo-- cast &lt;--MannerOf-- press</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>10</td>\n",
       "      <td>water</td>\n",
       "      <td>water</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>809 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     example question_context        choices  \\\n",
       "0          1       drawstring       military   \n",
       "1          1       drawstring        jewelry   \n",
       "2          1       drawstring  jewelry store   \n",
       "3          1       drawstring           safe   \n",
       "4          1       drawstring          store   \n",
       "..       ...              ...            ...   \n",
       "804       10            water           lift   \n",
       "805       10            water         bottle   \n",
       "806       10            water        suction   \n",
       "807       10            water          press   \n",
       "808       10            water          water   \n",
       "\n",
       "                                                  path  \n",
       "0    drawstring --PartOf--> drawstring bag --AtLoca...  \n",
       "1                                                   []  \n",
       "2    drawstring --PartOf--> drawstring bag --AtLoca...  \n",
       "3    drawstring --PartOf--> drawstring bag --AtLoca...  \n",
       "4    drawstring --PartOf--> drawstring bag --AtLoca...  \n",
       "..                                                 ...  \n",
       "804  water --HasContext--> dialectal <--HasContext-...  \n",
       "805                       water --AtLocation--> bottle  \n",
       "806                                                 []  \n",
       "807      water <--RelatedTo-- cast <--MannerOf-- press  \n",
       "808                                              water  \n",
       "\n",
       "[809 rows x 4 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df.index.name = \"index\"\n",
    "path_df.to_csv(\"../data/paths_examples.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Common Relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/en_edges.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/r/RelatedTo                    1703582\n",
       "/r/FormOf                        378859\n",
       "/r/DerivedFrom                   325374\n",
       "/r/HasContext                    232935\n",
       "/r/IsA                           230137\n",
       "/r/Synonym                       222156\n",
       "/r/UsedFor                        39790\n",
       "/r/EtymologicallyRelatedTo        32075\n",
       "/r/SimilarTo                      30280\n",
       "/r/AtLocation                     27797\n",
       "/r/HasSubevent                    25238\n",
       "/r/HasPrerequisite                22710\n",
       "/r/CapableOf                      22677\n",
       "/r/Antonym                        19066\n",
       "/r/Causes                         16801\n",
       "/r/PartOf                         13077\n",
       "/r/MannerOf                       12715\n",
       "/r/MotivatedByGoal                 9489\n",
       "/r/HasProperty                     8433\n",
       "/r/ReceivesAction                  6037\n",
       "/r/HasA                            5545\n",
       "/r/CausesDesire                    4688\n",
       "/r/dbpedia/genre                   3824\n",
       "/r/HasFirstSubevent                3347\n",
       "/r/DistinctFrom                    3315\n",
       "/r/Desires                         3170\n",
       "/r/dbpedia/genus                   2937\n",
       "/r/NotDesires                      2886\n",
       "/r/HasLastSubevent                 2874\n",
       "/r/DefinedAs                       2173\n",
       "/r/InstanceOf                      1480\n",
       "/r/dbpedia/influencedBy            1273\n",
       "/r/dbpedia/occupation              1043\n",
       "/r/dbpedia/language                 916\n",
       "/r/dbpedia/field                    643\n",
       "/r/dbpedia/knownFor                 607\n",
       "/r/MadeOf                           545\n",
       "/r/dbpedia/product                  519\n",
       "/r/dbpedia/capital                  459\n",
       "/r/Entails                          405\n",
       "/r/NotCapableOf                     329\n",
       "/r/NotHasProperty                   327\n",
       "/r/CreatedBy                        263\n",
       "/r/dbpedia/leader                    84\n",
       "/r/EtymologicallyDerivedFrom         71\n",
       "/r/LocatedNear                       49\n",
       "/r/SymbolOf                           4\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "591688fbcbea40ff8c02f2afe3b71c6c5dc57996febca89055592de027a69040"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
